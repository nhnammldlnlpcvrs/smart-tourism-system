{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec68bfe",
   "metadata": {},
   "source": [
    "# RAG + Rule-based Itinerary Generator\n",
    "\n",
    "Notebook n√†y th·ª±c hi·ªán:\n",
    "- Load d·ªØ li·ªáu `tourism_places` t·ª´ PostgreSQL.\n",
    "- Encode records b·∫±ng `sentence-transformers` (multilingual-e5-small).\n",
    "- X√¢y FAISS vector store (local, in-memory).\n",
    "- D√πng RAG (vector search) ƒë·ªÉ l·∫•y context li√™n quan.\n",
    "- T·∫°o l·ªãch tr√¨nh **rule-based** (chia s√°ng/tr∆∞a/chi·ªÅu/t·ªëi) d·ª±a tr√™n **selected places** t·ª´ c√°c tr∆∞·ªùng metadata (highlights, activities, duration_recommend, weather_notes, special_for, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673761a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (2.0.44)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nghoo\\appdata\\local\\anaconda3\\envs\\tourism\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu python-dotenv sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47bf48",
   "metadata": {},
   "source": [
    "## imports + dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4282a776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nghoo\\AppData\\Local\\anaconda3\\envs\\tourism\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Th∆∞ vi·ªán ML / DB\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sqlalchemy import create_engine, MetaData, Table, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd5735",
   "metadata": {},
   "source": [
    "## DB connection note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113bcea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine: Engine(postgresql+psycopg2://postgres:***@localhost:5432/tourismdb)\n",
      "DB connected: (1,)\n"
     ]
    }
   ],
   "source": [
    "DATABASE_URL = os.getenv(\"DATABASE_URL\") or \"postgresql+psycopg2://postgres:abc123@localhost:5432/tourismdb\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "print(\"Engine:\", engine)\n",
    "\n",
    "def load_postgres_data_dynamic(engine, table_names: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load rows from given table names. Return list of dicts: {\"id\": \"<table>:<id>\", \"record\": row_dict}\n",
    "    \"\"\"\n",
    "    metadata = MetaData()\n",
    "    results = []\n",
    "    with engine.begin() as conn:\n",
    "        for tbl_name in table_names:\n",
    "            table = Table(tbl_name, metadata, autoload_with=engine)\n",
    "            rows = conn.execute(table.select()).fetchall()\n",
    "            for r in rows:\n",
    "                row_dict = dict(r._mapping)\n",
    "                rid = row_dict.get(\"id\", None)\n",
    "                results.append({\n",
    "                    \"id\": f\"{tbl_name}:{rid}\",\n",
    "                    \"record\": row_dict\n",
    "                })\n",
    "    return results\n",
    "\n",
    "# Test connection quickly (optional)\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        r = conn.execute(text(\"SELECT 1\")).fetchone()\n",
    "        print(\"DB connected:\", r)\n",
    "except Exception as e:\n",
    "    print(\"DB connection error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef05a13",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1ffb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
    "\n",
    "def record_to_text(record: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Convert a DB record dict to a single text chunk for embedding.\n",
    "    Keep the most useful fields for retrieval: name, description, highlights, activities, tags, province, category.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    if record.get(\"name\"):\n",
    "        parts.append(str(record[\"name\"]))\n",
    "    if record.get(\"province\"):\n",
    "        parts.append(str(record[\"province\"]))\n",
    "    if record.get(\"category\"):\n",
    "        parts.append(str(record[\"category\"]))\n",
    "    # highlights\n",
    "    if record.get(\"highlights\"):\n",
    "        if isinstance(record[\"highlights\"], list):\n",
    "            parts.append(\"Highlights: \" + \", \".join(map(str, record[\"highlights\"])))\n",
    "        else:\n",
    "            parts.append(\"Highlights: \" + str(record[\"highlights\"]))\n",
    "    # activities\n",
    "    if record.get(\"activities\"):\n",
    "        if isinstance(record[\"activities\"], list):\n",
    "            parts.append(\"Activities: \" + \", \".join(map(str, record[\"activities\"])))\n",
    "        else:\n",
    "            parts.append(\"Activities: \" + str(record[\"activities\"]))\n",
    "    if record.get(\"description\"):\n",
    "        parts.append(str(record[\"description\"]))\n",
    "    if record.get(\"tags\"):\n",
    "        if isinstance(record[\"tags\"], list):\n",
    "            parts.append(\"Tags: \" + \", \".join(map(str, record[\"tags\"])))\n",
    "        else:\n",
    "            parts.append(\"Tags: \" + str(record[\"tags\"]))\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "def embed_texts(texts: List[str]) -> np.ndarray:\n",
    "    emb = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "    return emb.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0e26a",
   "metadata": {},
   "source": [
    "## VectorStore wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8330eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, vectors: np.ndarray, records: List[Dict[str, Any]]):\n",
    "        \"\"\"\n",
    "        vectors: numpy array (N, D)\n",
    "        records: parallel list of dicts (each contains 'id' and 'record')\n",
    "        \"\"\"\n",
    "        self.records = records\n",
    "        d = vectors.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(d)\n",
    "        self.index.add(vectors)\n",
    "\n",
    "    def search_by_vector(self, q_vec: np.ndarray, top_k: int = 5):\n",
    "        if q_vec.ndim == 1:\n",
    "            q_vec = q_vec.reshape(1, -1)\n",
    "        distances, indices = self.index.search(q_vec, top_k)\n",
    "        out = []\n",
    "        for idx in indices[0]:\n",
    "            if 0 <= idx < len(self.records):\n",
    "                out.append(self.records[idx])\n",
    "        return out\n",
    "\n",
    "    def search_by_text(self, text: str, top_k: int = 5):\n",
    "        q_emb = embed_texts([text])\n",
    "        return self.search_by_vector(q_emb, top_k=top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9bc8f",
   "metadata": {},
   "source": [
    "## Build store from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d571dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded records: 387\n",
      "Vectors shape: (387, 384)\n",
      "Vector store ready.\n"
     ]
    }
   ],
   "source": [
    "# Load tourism_places from postgres and build index (heavy step)\n",
    "table_names = [\"tourism_places\"]\n",
    "data = load_postgres_data_dynamic(engine, table_names)\n",
    "print(\"Loaded records:\", len(data))\n",
    "\n",
    "# Convert to text and embed\n",
    "texts = [record_to_text(r[\"record\"]) for r in data]\n",
    "vectors = embed_texts(texts)\n",
    "print(\"Vectors shape:\", vectors.shape)\n",
    "\n",
    "# Build store\n",
    "store = VectorStore(vectors, data)\n",
    "print(\"Vector store ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f8a92",
   "metadata": {},
   "source": [
    "## Rule-based itinerary generator (design)\n",
    "Quy t·∫Øc ch√≠nh:\n",
    "- Ng∆∞·ªùi d√πng ch·ªçn **place_ids** (√≠t nh·∫•t 1).\n",
    "- Ho·∫∑c input `province + days + preferences` => h·ªá th·ªëng s·∫Ω l·∫•y c√°c places t·ª´ DB theo province v√† filter theo preferences.\n",
    "- RAG (vector search) ƒë∆∞·ª£c d√πng ƒë·ªÉ l·∫•y th√™m **contexts** li√™n quan (top_k).\n",
    "- Rule-based scheduler s·∫Ω:\n",
    "  - S·∫Øp x·∫øp places theo `popularity_score` (n·∫øu c√≥) ho·∫∑c theo th·ª© t·ª± user ch·ªçn.\n",
    "  - G√°n 1‚Äì3 places/ng√†y: chia ra morning / noon / afternoon / evening (∆∞u ti√™n duration_recommend).\n",
    "  - M·ªói place output: name, address, highlights, activities, duration_recommend, price_range, open_hours, seasonal_events, special_for, weather_notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from collections import defaultdict\n",
    "\n",
    "def enrich_selected_places(selected_records: List[Dict[str, Any]], rag_contexts: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Selected_records: list of dicts each {\"id\":..., \"record\": {...}} or user-built dict.\n",
    "    rag_contexts: list of RAG hit objects (each has 'record' or 'raw')\n",
    "    Return enriched places list with useful fields.\n",
    "    \"\"\"\n",
    "    # build map by id or lower-name\n",
    "    by_id = {}\n",
    "    by_name = {}\n",
    "    for item in rag_contexts:\n",
    "        raw = item.get(\"raw\") or item.get(\"record\") or item.get(\"record\", {})\n",
    "        if not isinstance(raw, dict):\n",
    "            continue\n",
    "        rid = raw.get(\"id\")\n",
    "        name = raw.get(\"name\")\n",
    "        if rid is not None:\n",
    "            by_id[int(rid)] = raw\n",
    "        if isinstance(name, str):\n",
    "            by_name[name.strip().lower()] = raw\n",
    "\n",
    "    enriched = []\n",
    "    for rec in selected_records:\n",
    "        # rec may come as {\"id\":..., \"record\": {...}} OR normal place dict (from ORM)\n",
    "        if \"record\" in rec and isinstance(rec[\"record\"], dict):\n",
    "            r = rec[\"record\"]\n",
    "        else:\n",
    "            r = rec\n",
    "        meta = {\n",
    "            \"id\": r.get(\"id\"),\n",
    "            \"name\": r.get(\"name\"),\n",
    "            \"address\": r.get(\"address\"),\n",
    "            \"latitude\": r.get(\"latitude\"),\n",
    "            \"longitude\": r.get(\"longitude\"),\n",
    "            \"highlights\": r.get(\"highlights\") or [],\n",
    "            \"activities\": r.get(\"activities\") or [],\n",
    "            \"duration_recommend\": r.get(\"duration_recommend\"),\n",
    "            \"price_range\": r.get(\"price_range\"),\n",
    "            \"open_hours\": r.get(\"open_hours\"),\n",
    "            \"seasonal_events\": r.get(\"seasonal_events\") or [],\n",
    "            \"special_for\": r.get(\"special_for\") or [],\n",
    "            \"best_time_to_visit\": r.get(\"best_time_to_visit\"),\n",
    "            \"tags\": r.get(\"tags\") or [],\n",
    "            \"weather_notes\": r.get(\"weather_notes\"),\n",
    "            \"popularity_score\": float(r.get(\"popularity_score\") or 0.0)\n",
    "        }\n",
    "\n",
    "        # try to augment from rag_contexts (matching by id or name)\n",
    "        matched = None\n",
    "        try:\n",
    "            if meta[\"id\"] and int(meta[\"id\"]) in by_id:\n",
    "                matched = by_id[int(meta[\"id\"])]\n",
    "            else:\n",
    "                nm = meta[\"name\"]\n",
    "                if nm and nm.strip().lower() in by_name:\n",
    "                    matched = by_name[nm.strip().lower()]\n",
    "        except Exception:\n",
    "            matched = None\n",
    "\n",
    "        if matched:\n",
    "            # override sparse fields if present\n",
    "            for f in [\"highlights\", \"activities\", \"duration_recommend\", \"price_range\", \"open_hours\", \"seasonal_events\", \"special_for\", \"best_time_to_visit\", \"tags\", \"weather_notes\", \"popularity_score\"]:\n",
    "                if matched.get(f):\n",
    "                    meta[f] = matched.get(f) if not isinstance(matched.get(f), list) else matched.get(f)\n",
    "\n",
    "        enriched.append(meta)\n",
    "    return enriched\n",
    "\n",
    "def schedule_places(enriched_places: List[Dict[str, Any]], days: int):\n",
    "    \"\"\"\n",
    "    Very simple scheduler:\n",
    "    - sort by popularity_score desc\n",
    "    - chunk into roughly ceil(n / days) per day\n",
    "    - allocate into morning/noon/afternoon/evening depending on position and duration_recommend\n",
    "    \"\"\"\n",
    "    if days <= 0:\n",
    "        raise ValueError(\"days must be > 0\")\n",
    "    n = len(enriched_places)\n",
    "    per_day = max(1, ceil(n / days))\n",
    "    sorted_places = sorted(enriched_places, key=lambda x: x.get(\"popularity_score\", 0.0), reverse=True)\n",
    "    schedule = []\n",
    "    idx = 0\n",
    "    for d in range(1, days + 1):\n",
    "        day_block = {\"day\": d, \"slots\": {\"morning\": [], \"noon\": [], \"afternoon\": [], \"evening\": []}}\n",
    "        for s in range(per_day):\n",
    "            if idx >= n:\n",
    "                break\n",
    "            place = sorted_places[idx]\n",
    "            # assign slot heuristically: prefer longer durations to morning/afternoon multi-hour\n",
    "            dur = str(place.get(\"duration_recommend\") or \"\").lower()\n",
    "            if \"day\" in dur or \"ng√†y\" in dur or \"4\" in dur or \"2 ng√†y\" in dur:\n",
    "                # multi-day place: put in morning and possibly afternoon on same day (as summary)\n",
    "                day_block[\"slots\"][\"morning\"].append(place)\n",
    "            else:\n",
    "                # rotate slots: morning -> noon -> afternoon -> evening\n",
    "                slot_order = [\"morning\", \"noon\", \"afternoon\", \"evening\"]\n",
    "                slot = slot_order[(s) % 4]\n",
    "                day_block[\"slots\"][slot].append(place)\n",
    "            idx += 1\n",
    "        schedule.append(day_block)\n",
    "    return schedule\n",
    "\n",
    "def format_itinerary(schedule):\n",
    "    lines = []\n",
    "    for day in schedule:\n",
    "        d = day[\"day\"]\n",
    "        lines.append(f\"Day {d}**\\n\")\n",
    "        for slot in [\"morning\", \"noon\", \"afternoon\", \"evening\"]:\n",
    "            items = day[\"slots\"].get(slot, [])\n",
    "            if not items:\n",
    "                continue\n",
    "            # human-friendly slot name\n",
    "            slot_name = {\"morning\":\"S√°ng\",\"noon\":\"Tr∆∞a\",\"afternoon\":\"Chi·ªÅu\",\"evening\":\"T·ªëi\"}[slot]\n",
    "            lines.append(f\"{slot_name}: \" + (\"; \".join([p[\"name\"] for p in items])))\n",
    "            for p in items:\n",
    "                if p.get(\"activities\"):\n",
    "                    lines.append(f\"- Ho·∫°t ƒë·ªông: {', '.join(p.get('activities'))}\")\n",
    "                if p.get(\"weather_notes\"):\n",
    "                    lines.append(f\"- G·ª£i √Ω: {p.get('weather_notes')}\")\n",
    "                if p.get(\"highlights\"):\n",
    "                    lines.append(f\"- N·ªïi b·∫≠t: {', '.join(p.get('highlights'))}\")\n",
    "                if p.get(\"duration_recommend\"):\n",
    "                    lines.append(f\"- Th·ªùi gian: {p.get('duration_recommend')}\")\n",
    "                if p.get(\"price_range\"):\n",
    "                    lines.append(f\"- Gi√° tham kh·∫£o: {p.get('price_range')}\")\n",
    "                if p.get(\"open_hours\"):\n",
    "                    lines.append(f\"- Gi·ªù m·ªü: {p.get('open_hours')}\")\n",
    "                # blank line between places\n",
    "                lines.append(\"\")\n",
    "        lines.append(\"\")  # extra blank line per day\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d58267",
   "metadata": {},
   "source": [
    "## Top-level generator: from selected place_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea1764ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_itinerary_from_place_ids(place_ids: List[int], start_date: str, end_date: str, top_k_contexts: int = 6):\n",
    "    # days calculation\n",
    "    from datetime import datetime\n",
    "    s = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    e = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    if e < s:\n",
    "        raise ValueError(\"end_date < start_date\")\n",
    "    days = (e - s).days + 1\n",
    "\n",
    "    # load records for these ids from DB\n",
    "    # Simple approach: query tourism_places by id\n",
    "    conn = engine.connect()\n",
    "    md = MetaData()\n",
    "    tbl = Table(\"tourism_places\", md, autoload_with=engine)\n",
    "    rows = conn.execute(tbl.select().where(tbl.c.id.in_(place_ids))).fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    selected_records = [{\"id\": r._mapping.get(\"id\"), \"record\": dict(r._mapping)} for r in rows]\n",
    "\n",
    "    # RAG: build query from place names (fallback)\n",
    "    names = [r[\"record\"].get(\"name\") for r in selected_records if r[\"record\"].get(\"name\")]\n",
    "    query = \" \".join(names)\n",
    "    contexts = store.search_by_text(query, top_k=top_k_contexts)\n",
    "\n",
    "    # Enrich selected places\n",
    "    enriched = enrich_selected_places(selected_records, contexts)\n",
    "\n",
    "    # schedule\n",
    "    schedule = schedule_places(enriched, days)\n",
    "\n",
    "    # format text\n",
    "    itinerary_text = format_itinerary(schedule)\n",
    "\n",
    "    return {\n",
    "        \"province\": enriched[0].get(\"province\") if enriched else None,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"days\": days,\n",
    "        \"selected_count\": len(enriched),\n",
    "        \"rag_contexts_used\": contexts,\n",
    "        \"schedule\": schedule,\n",
    "        \"itinerary_text\": itinerary_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c659a",
   "metadata": {},
   "source": [
    "## Run example with your sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ITINERARY TEXT ===\n",
      "\n",
      "üóìÔ∏è **Day 1**\n",
      "\n",
      "**S√°ng:** Hang S∆°n ƒêo√≤ng\n",
      "- Ho·∫°t ƒë·ªông: Th√°m hi·ªÉm chuy√™n nghi·ªáp, C·∫Øm tr·∫°i trong hang, B∆°i hang\n",
      "- G·ª£i √Ω: Y√™u c·∫ßu th·ªÉ l·ª±c cao\n",
      "- N·ªïi b·∫≠t: B·ª©c t∆∞·ªùng Vi·ªát Nam, V∆∞·ªùn ƒê·ªãa ƒê√†ng, H·ªë s·ª•t\n",
      "- Th·ªùi gian: 4 ng√†y 3 ƒë√™m\n",
      "- Gi√° tham kh·∫£o: 3.000 USD (Tour th√°m hi·ªÉm)\n",
      "- Gi·ªù m·ªü: Theo tour ƒë·∫∑t tr∆∞·ªõc\n",
      "\n",
      "\n",
      "üóìÔ∏è **Day 2**\n",
      "\n",
      "**S√°ng:** Hang √ân\n",
      "- Ho·∫°t ƒë·ªông: Trekking r·ª´ng, C·∫Øm tr·∫°i, T·∫Øm su·ªëi\n",
      "- G·ª£i √Ω: ƒêi b·ªô ƒë∆∞·ªùng d√†i\n",
      "- N·ªïi b·∫≠t: B√£i tr·∫°i trong hang, C·ª≠a hang kh·ªïng l·ªì, Chim √©n\n",
      "- Th·ªùi gian: 2 ng√†y 1 ƒë√™m\n",
      "- Gi√° tham kh·∫£o: 7-9 tri·ªáu VNƒê (Tour)\n",
      "- Gi·ªù m·ªü: Theo tour\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example run using your sample place IDs\n",
    "sample_place_ids = [339, 385]  # Hang S∆°n ƒêo√≤ng, Hang √ân\n",
    "start_date = \"2025-06-01\"\n",
    "end_date = \"2025-06-02\"\n",
    "\n",
    "out = generate_itinerary_from_place_ids(sample_place_ids, start_date, end_date, top_k_contexts=6)\n",
    "print(\"=== ITINERARY TEXT ===\\n\")\n",
    "print(out[\"itinerary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277fd51f",
   "metadata": {},
   "source": [
    "## Conclusion: How the RAG System Works in This Project\n",
    "\n",
    "H·ªá th·ªëng Recommendation s·ª≠ d·ª•ng k·ªπ thu·∫≠t RAG (Retrieval-Augmented Generation) ƒë·ªÉ t·∫°o g·ª£i √Ω h√†nh tr√¨nh du l·ªãch ch√≠nh x√°c, ph√π h·ª£p v·ªõi nhu c·∫ßu ng∆∞·ªùi d√πng d·ª±a tr√™n d·ªØ li·ªáu ƒë·ªãa ƒëi·ªÉm c√≥ s·∫µn.\n",
    "M·∫∑c d√π project kh√¥ng c√≤n s·ª≠ d·ª•ng LLM ƒë·ªÉ sinh vƒÉn b·∫£n d√†i, ki·∫øn tr√∫c RAG v·∫´n gi·ªØ vai tr√≤ quan tr·ªçng trong l·∫•y d·ªØ li·ªáu ‚Äì l·ªçc ‚Äì suy lu·∫≠n ‚Äì gh√©p h√†nh tr√¨nh.\n",
    "\n",
    "### 1. Data Retrieval (Truy xu·∫•t d·ªØ li·ªáu)\n",
    "\n",
    "- Ng∆∞·ªùi d√πng nh·∫≠p v√†o c√°c tham s·ªë nh∆∞:\n",
    "\n",
    "    - province\n",
    "\n",
    "    - days\n",
    "\n",
    "    - interests, pace, group_type, time_preferences\n",
    "\n",
    "- H·ªá th·ªëng s·ª≠ d·ª•ng ch√∫ng ƒë·ªÉ truy v·∫•n database v√† l·∫•y ra danh s√°ch c√°c ƒë·ªãa ƒëi·ªÉm c√≥:\n",
    "\n",
    "    - Ph√π h·ª£p s·ªü th√≠ch\n",
    "\n",
    "    - N·∫±m trong t·ªânh t∆∞∆°ng ·ª©ng\n",
    "\n",
    "    - Kh√¥ng n·∫±m trong avoid_categories\n",
    "\n",
    "- K·∫øt qu·∫£ retrieval cho ra t·∫≠p c√°c ƒë·ªãa ƒëi·ªÉm ·ª©ng vi√™n.\n",
    "\n",
    "### 2. Ranking (X·∫øp h·∫°ng ƒë·ªô ph√π h·ª£p)\n",
    "\n",
    "- M·ªói ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c ch·∫•m ƒëi·ªÉm theo c√°c y·∫øu t·ªë:\n",
    "\n",
    "    - M·ª©c ƒë·ªô tr√πng kh·ªõp interests\n",
    "\n",
    "    - Ph√π h·ª£p v·ªõi th·ªùi gian trong ng√†y\n",
    "\n",
    "    - ƒê·ªãa ƒëi·ªÉm c√≥ weather_notes, duration_recommend h·ª£p l√Ω\n",
    "\n",
    "    - Lo·∫°i h√¨nh ph√π h·ª£p v·ªõi pace (chill/medium/full)\n",
    "\n",
    "    - G·ª£i √Ω theo group_type (family, adventure, couple‚Ä¶)\n",
    "\n",
    "- ƒêi·ªÉm t·ªïng h·ª£p ‚Üí X·∫øp th·ª© t·ª± ∆∞u ti√™n ‚Üí Ch·ªçn nh·ªØng ƒëi·ªÉm t·ªët nh·∫•t.\n",
    "\n",
    "### 3. Generation\n",
    "\n",
    "H·ªá th·ªëng d√πng:\n",
    "\n",
    "- Template markdown\n",
    "\n",
    "- Rule-based formatting\n",
    "\n",
    "- Logic ph√¢n ng√†y v√† ph√¢n bu·ªïi\n",
    "\n",
    "V√≠ d·ª•:\n",
    "\n",
    "- Bu·ªïi s√°ng ∆∞u ti√™n tham quan/ch·ª•p ·∫£nh\n",
    "\n",
    "- Bu·ªïi chi·ªÅu ∆∞u ti√™n kh√°m ph√°, v·∫≠n ƒë·ªông\n",
    "\n",
    "- T·ªëi ∆∞u ti√™n ngh·ªâ ng∆°i ho·∫∑c city tour\n",
    "\n",
    "H·ªá th·ªëng t·ª± ƒë·ªông:\n",
    "\n",
    "- Chia l·ªãch theo days\n",
    "\n",
    "- Ph√¢n b·ªï ƒë·ªãa ƒëi·ªÉm theo time_preferences\n",
    "\n",
    "- Gh√©p th√™m activities, highlights, weather notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tourism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
