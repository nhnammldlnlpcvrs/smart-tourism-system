'''
from llm_agent import LLMAgent

if __name__ == "__main__":
    agent = LLMAgent()

    while True:
        user_input = input("B·∫°n: ")
        if user_input.lower() in ["exit", "quit"]:
            break

        reply = agent.handle_query(user_input)
        print("ü§ñ LLM:", reply)


from fastapi import FastAPI
from pydantic import BaseModel
from llm_agent import LLMAgent

app = FastAPI(title="Weather + LLM API", description="API k·∫øt h·ª£p Open-Meteo v√† ChatGPT", version="1.0")

agent = LLMAgent()

class QueryRequest(BaseModel):
    message: str

@app.get("/")
def root():
    return {"message": "Welcome to Weather LLM API"}

@app.post("/ask")
def ask_weather(req: QueryRequest):
    """API ch√≠nh ƒë·ªÉ h·ªèi LLM"""
    reply = agent.handle_query(req.message)
    return {"reply": reply}
'''


import sys, os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from fastapi import FastAPI
from pydantic import BaseModel
from services.llm_agent import LLMAgent  # <- import t∆∞∆°ng ƒë·ªëi

app = FastAPI(
    title="Weather + LLM API",
    description="API k·∫øt h·ª£p Open-Meteo v√† ChatGPT",
    version="1.0"
)

agent = LLMAgent()

class QueryRequest(BaseModel):
    message: str

@app.get("/")
def root():
    return {"message": "Welcome to Weather LLM API"}

@app.post("/ask")
def ask_weather(req: QueryRequest):
    """G·ª≠i c√¢u h·ªèi ƒë·∫øn LLM ho·∫∑c l·∫•y th·ªùi ti·∫øt"""
    reply = agent.handle_query(req.message)
    return {"reply": reply}

import uvicorn

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000, reload=True)

